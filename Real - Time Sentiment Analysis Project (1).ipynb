{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d87ae10f",
   "metadata": {},
   "source": [
    "# Real-Time Sentiment Analysis Project\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a real-time sentiment analysis using data extracted from online articles about eSports and gaming in India. We analyze sentiments to understand public opinion dynamically, which can significantly impact decision-making processes in various domains.\n",
    "\n",
    "## Objectives\n",
    "- Fetch and analyze articles in real-time.\n",
    "- Classify sentiments into categories: Very Positive, Positive, Neutral, Negative, and Very Negative.\n",
    "- Visualize the distribution of sentiments across the articles.\n",
    "\n",
    "## Benefits of Real-Time Sentiment Analysis\n",
    "- **Timely Insights:** Allows for the immediate understanding of public sentiments, crucial for rapid response strategies.\n",
    "- **Proactive Decision Making:** Facilitates quick decisions based on current public mood or opinion.\n",
    "- **Enhanced Customer Experiences:** Enables organizations to react promptly to customer feedback, improving engagement and satisfaction.\n",
    "- **Competitive Advantage:** Helps in staying ahead by understanding market trends and public opinion in real-time.\n",
    "- **Crisis Management:** Aids in managing public relations crises more effectively by providing immediate data.\n",
    "- **Scale and Automation:** Supports handling large volumes of data simultaneously, providing broader insights without manual effort.\n",
    "\n",
    "## Installation Instructions\n",
    "-  To install the required libraries, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32f392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Required Libraries\n",
    "!pip install pandas httpx aiohttp beautifulsoup4 sumy nest_asyncio matplotlib seaborn nltk spacy gensim google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca415473",
   "metadata": {},
   "source": [
    "### Code for Fetching Articles to collect and analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas httpx aiohttp beautifulsoup4 nest_asyncio matplotlib seaborn nltk spacy gensim google textblob\n",
    "import pandas as pd\n",
    "import httpx\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "import nest_asyncio\n",
    "import logging\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Apply necessary asyncio adjustments for Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set up logging for debugging\n",
    "logging.basicConfig(level=logging.WARNING)  # Only log warnings and above\n",
    "\n",
    "async def fetch_article_content(url):\n",
    "    \"\"\"Asynchronously fetch content from a URL using httpx with a user-agent.\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "        }\n",
    "        async with httpx.AsyncClient(timeout=10.0, follow_redirects=True, headers=headers) as client:\n",
    "            response = await client.get(url)\n",
    "            response.raise_for_status()  # Ensure the request was successful\n",
    "            return response.text\n",
    "    except httpx.RequestError as e:\n",
    "        logging.error(f\"Request error for {url}: {str(e)}\")\n",
    "        return None\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        logging.error(f\"HTTP status error for {url}: {e.response.status_code} - {e.response.reason_phrase}\")\n",
    "        return None\n",
    "\n",
    "async def process_articles(urls):\n",
    "    \"\"\"Process a list of URLs to fetch their content.\"\"\"\n",
    "    contents = []\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        tasks = [fetch_article_content(url) for url in urls]\n",
    "        responses = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        for response in responses:\n",
    "            if response and isinstance(response, str):  # Handle article content\n",
    "                soup = BeautifulSoup(response, 'html.parser')\n",
    "                text = ' '.join(p.get_text(strip=True) for p in soup.find_all('p'))\n",
    "                if text:\n",
    "                    contents.append(text)\n",
    "                else:\n",
    "                    contents.append(\"No content available\")\n",
    "            else:\n",
    "                contents.append(\"No content available\")\n",
    "    return contents\n",
    "\n",
    "async def add_content_to_df(query):\n",
    "    \"\"\"Main function to manage the workflow from search to DataFrame creation.\"\"\"\n",
    "    urls = perform_google_search(query, max_results=100)\n",
    "    contents = await process_articles(urls)\n",
    "    df = pd.DataFrame(contents, columns=['content'])\n",
    "    df = df[df['content'] != \"No content available\"]\n",
    "    return df\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0.1:\n",
    "        return 'Positive'\n",
    "    elif polarity < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "def perform_google_search(query, max_results=100):\n",
    "    \"\"\"Perform a Google search and collect up to max_results URLs, focusing on articles only.\"\"\"\n",
    "    results = []\n",
    "    try:\n",
    "        search_query = f\"{query} -site:youtube.com -site:vimeo.com\"\n",
    "        for result in search(search_query):\n",
    "            results.append(result)\n",
    "            if len(results) >= max_results:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred while fetching the results: \" + str(e))\n",
    "    return results\n",
    "\n",
    "# User interaction to enter the search query\n",
    "user_query = input(\"Please enter your search query: \")\n",
    "\n",
    "# Run the process and update DataFrame with contents\n",
    "df = await add_content_to_df(user_query)\n",
    "\n",
    "# Apply sentiment analysis to the DataFrame\n",
    "df['sentiment'] = df['content'].apply(classify_sentiment)\n",
    "\n",
    "# Calculate the counts and percentages of each sentiment category\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "sentiment_percentages = sentiment_counts / len(df) * 100\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(sentiment_percentages, labels=sentiment_percentages.index, autopct='%1.1f%%', startangle=140, colors=['#FF9999', '#66B3FF', '#99FF99', '#FFCC99', '#FFD700'])\n",
    "plt.title('Sentiment Distribution in Articles')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Determine the overall sentiment based on the highest percentage\n",
    "overall_sentiment = sentiment_percentages.idxmax()\n",
    "\n",
    "# Output the overall sentiment\n",
    "print(f\"The overall sentiment is {overall_sentiment}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2563ed4",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provided a demonstration of real-time sentiment analysis applied to online articles about any query. The insights derived from this analysis can be utilized to make informed decisions, improve customer interactions, and adapt strategies in real-time based on public sentiment.\n",
    "\n",
    "## Conclusion\n",
    "If you would like to contribute to this project, please follow these guidelines:\n",
    "\n",
    "- Fork the repository.\n",
    "- Create a new branch (git checkout -b feature-branch).\n",
    "- Make your changes.\n",
    "- Commit your changes (git commit -m 'Add some feature').\n",
    "- Push to the branch (git push origin feature-branch).\n",
    "- Create a new Pull Request.\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "- Thanks to the developers of the libraries used in this project.\n",
    "- Special thanks to the community for the support and contributions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
